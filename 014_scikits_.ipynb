{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import mglearn # 학습을 위해 만들어진.. 시각화됨\n",
    "\n",
    "# 랜덤하게 사이즈를 채운 후 행렬 제곱을 하면 정방행렬이면서 대칭행렬인 것으로 변한다\n",
    "# 고유값분해 => 고유치와 고유벡터(정직교)가 나옴\n",
    "\n",
    "# 어제배운 MDS는 행렬곱(직교하는 2 or 3차원) => 2차원이나 3차원 특징을 추출 : 2,3차원의 시각화에 도움\n",
    "\n",
    "# MLP : Multi layer perceptron : FFNN(Feed forword neural network)\n",
    "# 순전파(forward propagation) : 예측 or 분류과정 (가중치가 random하게 초기화, 가중치학습을 위해선 역전파필요)\n",
    "# 역전파(backward propagation) : 가중치 학습과정 (cost function 기울기, )\n",
    "\n",
    "# solver의 역할 : 미분, learning-rate 조절, => 가중치 조절\n",
    "# estimator, transformer\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier # MLP에는 Classifier와 Regressor가 있다.\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = make_moons(n_samples=100, noise=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify 층화 변수 선택법 : 층화?\n",
    "# 무작위로 하는 게 아니라 대상 값의 비율을 맞추는 것\n",
    "# 하기에서의 y값을 비율로 나누어\n",
    "\n",
    "# Multi layer => XOR문제를 해결하기 위해, 레이어가 많으면 정밀도를 자동으로 높아지기 때문\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y, random_state=42)\n",
    "\n",
    "# 가중치가 완성 - MLPClassifier가 자동으로 레이어 가중치 지정\n",
    "mlp = MLPClassifier(random_state=0).fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "mglearn.discrete_scatter(X_train[:,0], X_train[:,1], y_train)\n",
    "plt.xlabel(\"feature 0\")\n",
    "plt.ylabel(\"feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.get_params() # 디폴트 매개변수\n",
    "# activation : relu ? -> 0 이하를 제거한 활성화 함수 -> 속도가 빨라짐\n",
    "# epoch 1회반복\n",
    "# adam : learning-rate를 조절, Momentum을 사용하는 optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.n_layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.coefs_ # coefficient # bias: 계수들이 0으로 가는 것을 방지해서 처음에 1로 세팅됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', random_state=0, hidden_layer_sizes=[10, 5,2])\n",
    "# SVM의 논리 :고차원으로 데이터 확대(고차원을 선호하는 모델)\n",
    "    # - 정확도가 높아\n",
    "    # - 과적합을 방지\n",
    "    # SVC, SVR\n",
    "    \n",
    "# 히든 레이어 사이즈에서 지정하는 것은 무엇인가?\n",
    "# -> 출력차수만 지정(즉, 추출할 특징 수)\n",
    "# 여러개 줄수있긴함.\n",
    "\n",
    "# 레어어가 10개 이상 주면 기울기 소실 문제가 발생함\n",
    "#\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3)\n",
    "\n",
    "mglearn.discrete_scatter(X_train[:,0], X_train[:,1], y_train)\n",
    "plt.xlabel(\"feature 0\")\n",
    "plt.ylabel(\"feature 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Black box -> 요즘에는 블랙박스를 원인규명해내겠다는 시도도 있다\n",
    "\n",
    "mlp.coefs_\n",
    "# 2 x 10\n",
    "# bias 가 10\n",
    "\n",
    "# 변수는 2x10 , 10x10 # 10으로 나감\n",
    "# 변수 2개인건 x,y좌표로 표기된거라서 그럴거임.\n",
    "\n",
    "# 2x5 , 5x10\n",
    "\n",
    "# adam과 lbfgs 비교시 adam이 더 일반화하려는 경향이 있음을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 / 다항에 대한 비선형 회귀와 같다\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 8))\n",
    "for axx, n_hidden_nodes in zip(axes, [10, 100]):\n",
    "    for ax, alpha in zip(axx, [0.0001, 0.01, 0.1, 1]):\n",
    "        mlp = MLPClassifier(solver='lbfgs', random_state=0,\n",
    "                            hidden_layer_sizes=[n_hidden_nodes, n_hidden_nodes],\n",
    "                            alpha=alpha)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        mglearn.plots.plot_2d_separator(mlp, X_train, fill=True, alpha=.3, ax=ax)\n",
    "        mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train, ax=ax)\n",
    "        ax.set_title(\"n_hidden=[{}, {}]\\nalpha={:.4f}\".format(\n",
    "                      n_hidden_nodes, n_hidden_nodes, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(\"유방암 데이터의 특성별 최대값 : \\n{}\".format(cancer.data.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "mlp = MLPClassifier(random_state = 42) # 디폴트 \n",
    "mlp.fit(X_train, y_train) # 가중치 결정\n",
    "\n",
    "print(\"훈련 세트 정확도 : {:.2f}\".format(mlp.score(X_train, y_train))) # parameter tuning\n",
    "print(\"테스트 세트 정확도 : {:.2f}\".format(mlp.score(X_test, y_test)))\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 세트 각 특성의 평균을 계산합니다.\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "# 훈련 세트 각 특성의 표준 편차를 계산합니다.\n",
    "std_on_train = X_train.std(axis=0)\n",
    "\n",
    "# Z점수 표준화\n",
    "# 데이터에서 평균을 빼고 표준 편차로 나누면\n",
    "# 평균 0, 표준 편차 1인 데이터로 변환됩니다.\n",
    "X_train_scaled = (X_train - mean_on_train) / std_on_train\n",
    "# (훈련 데이터의 평균과 표준 편차를 이용해) 같은 변환을 테스트 세트에도 합니다.\n",
    "X_test_scaled = (X_test - mean_on_train) / std_on_train\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=1000, random_state=0) # 1000 번 반복해라\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 알파값을 바꿔보자 (규제를 줘보자)\n",
    "\n",
    "mlp = MLPClassifier(max_iter=1000, alpha = 1, random_state=0)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "print(\"훈련 세트 정확도 : {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n",
    "plt.yticks(range(30), cancer.feature_names)\n",
    "plt.xlabel(\"은닉 유닛\")\n",
    "plt.ylabel(\"입력 특성\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wine = pd.read_csv('./wine_data.csv', names = [\"Cultivator\", \"Alchol\", \"Malic_Acid\", \"Ash\",\n",
    "                                             \"Alcalinity_of_Ash\", \"Magnesium\", \"Total_phenols\",\n",
    "                                             \"Falvanoids\", \"Nonflavanoid_phenols\",\n",
    "                                             \"Proanthocyanins\", \"Color_intensity\", \"Hue\",\n",
    "                                             \"OD280\", \"Proline\"], encoding=\"utf-8\") \n",
    "wine\n",
    "# 178관측치, 14변수\n",
    "# 분류 : 독립변수와 종속변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 : wineMLP 분류\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(wine.loc[:,'Alchol':'Proline'],wine.loc[:,'Cultivator'])\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print(\"훈련 : {:.3f}\".format(mlp.score(X_train, y_train)))\n",
    "print(\"테스트 : {:.3f}\".format(mlp.score(X_test, y_test)), '\\n')\n",
    "\n",
    "\n",
    "####\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_train_mean = X_train.mean(axis=0)\n",
    "X_train_std = X_train.std(axis=0)\n",
    "\n",
    "X_train_scaled = (X_train - X_train_mean) / X_train_std\n",
    "X_test_scaled = (X_test - X_train_mean) / X_train_std\n",
    "\n",
    "print(\"z점수 스케일 훈련 : {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"z점수 스케일 테스트 : {:.3f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선생님 문제풀이\n",
    "\n",
    "X = wine.drop('Cultivator', axis=1)\n",
    "y = wine['Cultivator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# StandardScaler(copy=True, with_mean=True, with_std=True)  | 카피 True : 원본은 그대로 두고..\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# 히든 레이어 사이즈의 디폴트는 100이다.\n",
    "# hidden_layer_sizes(100,)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes = (30,30,30))\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "from sklearn.metrics import classification_report\n",
    "# pricision : 정밀도 = TP / (TP+FP) : 예측을 중심으로 생각\n",
    "# recall : 재현율 = TP / (TP+TN) : 실제값을 중심으로 생각\n",
    "# f1-score F점수 : 2*(pricision*recall) / (precision + recall)\n",
    "# support : 총 개수\n",
    "# 매트릭스에 맞춘개수 나옴\n",
    "\n",
    "# 행 1,2,3의 의미 : unique해서 나왔던 분류대상\n",
    "# accuracy : 정확도\n",
    "# macro avg : 단순평균\n",
    "# weighted avg : 가중평균\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlp.coefs_[0].shape) # 13 x 30\n",
    "print(mlp.coefs_[1].shape) # 30 x n (지정 30)\n",
    "print(mlp.coefs_[2].shape) # n x m (지정 30)\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.imshow(mlp.coefs_[0], interpolation = 'none', cmap='viridis')\n",
    "plt.xlabel(\"은닉 유닛\")\n",
    "plt.ylabel(\"입력 특성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF( Non-negative matrix factorization) : 비음수 행렬 분해\n",
    "\n",
    "- PCA는 음수와 양수의 차이를 상계해서 처리\n",
    "- NMF는 양수인 데이터에 적용해서 분해를 해줌 : 음성데이터, signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터\n",
    "S = mglearn.datasets.make_signals()\n",
    "plt.figure(figsize=(6,1))\n",
    "plt.plot(S,'-')\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"signal\")\n",
    "plt.margins(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터에 노이즈 포함\n",
    "# 노이즈 : 전송 데이터\n",
    "import numpy as np\n",
    "\n",
    "A = np.random.RandomState(0).uniform(size=(100,3))\n",
    "X = np.dot(S,A.T)\n",
    "print(\"측정 데이터 형태 : {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF으로 decomposition한 데이터\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "nmf = NMF(n_components = 3, random_state=42)\n",
    "S_=nmf.fit_transform(X)\n",
    "print(\"복원한 신호 데이터 형태 : {}\".format(S_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA로 decomposition한 데이터\n",
    "pca = PCA(n_components = 3)\n",
    "H = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(\n",
    "fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본, 노이즈, NMF, PCA\n",
    "models = [S, X, S_, H]\n",
    "names = ['측정 신호(처음3개)', '원본 신호', 'NMF로 복원한 신호', 'PCA로 복원한 신호']\n",
    "fig, axes = plt.subplots(4, figsize=(8,4), gridspec_kw={'hspace':.5},\n",
    "                        subplot_kw={'xticks':(), 'yticks':()})\n",
    "\n",
    "for model, name, ax in zip(models, names, axes):\n",
    "    ax.set_title(name)\n",
    "    ax.plot(model[:, :3], '-')\n",
    "    ax.margins(0)\n",
    "    \n",
    "# PCA는 양수 데이터 노이즈를 제거하지 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 군집 분석 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.io.stata.read_stata(\"koweps_h01_13_long_beta1.dta\")\n",
    "data.to_csv('m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "data = './koweps_h01_13_long_beta1.dta'\n",
    "df, meta = pyreadstat.read_dta(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
